# Gestione degli imports:
import os
from skimage import filters
from skimage import io
from skimage.io import imread
from skimage import data, color
from skimage.transform import rescale, resize, downscale_local_mean
from skimage.feature import hog
from sklearn.model_selection import train_test_split
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.linear_model import SGDClassifier
from sklearn.model_selection import cross_val_predict
from sklearn.preprocessing import StandardScaler, Normalizer
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn import svm

import cv2 as cv

# Per dataset pickle:
import joblib

# Varie ed eventuali
from collections import Counter
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

resize_x = 64
resize_y = 128

#-----------------------------------------------------------------------------------------------------------------------#
# VARIABILI BOOLEANE DEL PROGRAMMA:
prepare_data = False
prepare_dataset = True
print_dataset_info = True

#-----------------------------------------------------------------------------------------------------------------------#
# TRASFORMATORE PER ESTRARRE GLI HISTOGRAM OF ORIENTED GRADIENTS:

class HogTransformer(BaseEstimator, TransformerMixin):
    """
    Expects an array of 2d arrays (1 channel images)
    Calculates hog features for each img
    """
    def __init__(self, y=None, orientations=9,
            pixels_per_cell=(8, 8),
            cells_per_block=(3, 3), block_norm='L2-Hys'):
        self.y = y
        self.orientations = orientations
        self.pixels_per_cell = pixels_per_cell
        self.cells_per_block = cells_per_block
        self.block_norm = block_norm

    def fit(self, X, y=None):
        return self

    def transform(self, X, y=None):

        def local_hog(X):
            return hog(X,
                orientations=self.orientations,
                pixels_per_cell=self.pixels_per_cell,
                cells_per_block=self.cells_per_block,
                block_norm=self.block_norm)
        
        try: # parallel
            return np.array([local_hog(img) for img in X])
        except:
            return np.array([local_hog(img) for img in X])

#-----------------------------------------------------------------------------------------------------------------------#
# ACQUISISCO LE IMMAGINI DALLA WEBCAM CON OPENCV, LE SALVO IN CARTELLE APPOSITE:

def equalize_imgs(img):
    R, G, B = cv.split(img)
    output1_R = cv.equalizeHist(R)
    output1_G = cv.equalizeHist(G)
    output1_B = cv.equalizeHist(B)
    equ = cv.merge((output1_R, output1_G, output1_B))
    return equ

if prepare_data:
    print("Connecting to camera...")
    camera = cv.VideoCapture(0)
    print("Connection estabilished")

    keyboard = input("Insert text: ")
    match keyboard:
        case '1':
            for i in range(200):
                ret, frame = camera.read()
                equ = equalize_imgs(frame)
                cv.imwrite("./class_1/class_1_{}.jpg".format(i), equ)
        case '2':
            for i in range(200):
                ret, frame = camera.read()
                equ = equalize_imgs(frame)
                cv.imwrite("./class_2/class_2_{}.jpg".format(i), equ)

        case _:
            print("Case out of bounds")

#-----------------------------------------------------------------------------------------------------------------------#
# PREPARO IL MIO DATASET IN FORMATO .PKL:

if prepare_dataset:
    path = "./"

    files = os.listdir(path)

    classes = {}

    for element in files:
        if (not element.endswith(".py")):
            img_path = path + element
            images = os.listdir(img_path)
            for image_number in range(len(images)):
                images[image_number] = img_path + "/" + images[image_number]
            classes[element] = images

    # Ora ho un dizionario cos√¨ composto:
    # 'class_1' : ['./class_1/image0.jpg', './class_1/image1.jpg', ...]

    # Preparo il dataset applicando trasformazioni alle immagini:
    dataset = dict()
    dataset['description'] = 'My dataset composed of two classes, namely C1 and C2'
    dataset['label'] = []
    dataset['filename'] = []
    dataset['data'] = []
    pklname = f"" + str(resize_y) + "px" + str(resize_x) + "px.pkl"

    for elements in classes:
        for image_number in classes[elements]:
            work_on_image = io.imread(image_number)
            work_on_image = resize(work_on_image, (resize_y, resize_x), anti_aliasing=True)
            work_on_image = color.rgb2gray(work_on_image)
            print("class: {} - image number: {}".format(elements, image_number))
            dataset['label'].append(elements)
            dataset['filename'].append(image_number)
            dataset['data'].append(work_on_image)

    joblib.dump(dataset, pklname)

#-----------------------------------------------------------------------------------------------------------------------#
# ADDESTRO IL CLASSIFICATORE, FACENDO LOADING DEI DATI:

# data = joblib.load(f'{}px{}px.pkl'.format(resize_y, resize_x))
data = joblib.load(f"" + str(resize_y) + "px" + str(resize_x) + "px.pkl")

if print_dataset_info:
    print('number of samples: ', len(data['data']))
    print('keys: ', list(data.keys()))
    print('description: ', data['description'])
    print('image shape: ', data['data'][0].shape)
    print('labels:', np.unique(data['label']))
    Counter(data['label'])

labels = np.unique(data['label'])

X = np.array(data['data'])
y = np.array(data['label'])

X_train, X_test, y_train, y_test = train_test_split(
    X, 
    y, 
    test_size=0.2, 
    shuffle=True,
    random_state=42,
)

hogify = HogTransformer(
    pixels_per_cell = (8, 8), 
    cells_per_block = (2, 2), 
    orientations = 9, 
    block_norm = 'L2-Hys'
)

scalify = StandardScaler()

# call fit_transform on each transform converting X_train step by step
X_train_hog = hogify.fit_transform(X_train)
X_train_prepared = scalify.fit_transform(X_train_hog)

print(X_train_prepared.shape)

sgd_clf = SGDClassifier(random_state=42, max_iter=1000, tol=1e-3)
sgd_clf.fit(X_train_prepared, y_train)

# Effettuo le trasformazioni sui sample di test:
X_test_hog = hogify.transform(X_test)
X_test_prepared = scalify.transform(X_test_hog)

#-----------------------------------------------------------------------------------------------------------------------#
# EFFETTUO I TEST:

y_pred = sgd_clf.predict(X_test_prepared)
print(np.array(y_pred == y_test)[:10])
print('')
print('Percentage correct: ', 100*np.sum(y_pred == y_test)/len(y_test))

#-----------------------------------------------------------------------------------------------------------------------#

# save the model to disk
joblib.dump(sgd_clf, 'sgd_model.pkl')

print("Model saved on disk.")
